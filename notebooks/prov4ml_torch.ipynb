{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prov4ML Torch Example\n",
    "\n",
    "This notebook is a simple example of how to use Prov4ML with Pytorch and the MNIST dataset. The task is simple digit classification using an MLP model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the necessary libraries and defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import prov4ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "PATH_DATASETS = \"./data\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating experiment, run and instantiate context\n",
    "\n",
    "Initialize a new run within an experiment and start logging provenance data. \n",
    "This call specifies a user namespace, naming the experiment, defining the directory for saving provenance logs, and setting the logging frequency. \n",
    " - **prov_user_namespace**: The unique identifier for the user or organization, ensuring the provenance data is correctly attributed.\n",
    " - **experiment_name**: The name of the experiment, used to group related runs together.\n",
    " - **provenance_save_dir**: The directory where the provenance logs are stored.\n",
    " - **save_after_n_logs**: The interval for saving logs to file, to empty the variables saved in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov4ml.start_run(\n",
    "    prov_user_namespace=\"www.example.org\",\n",
    "    experiment_name=\"experiment_name\", \n",
    "    provenance_save_dir=\"prov\",\n",
    "    save_after_n_logs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the model and the datasets\n",
    "\n",
    "Prov4ml allows to log various metrics and parameters to ensure comprehensive tracking of the experiment’s provenance.\n",
    "- **log_metric**: Logs a metric value to the provenance data, keeping track of the value, time, epoch and context.\n",
    "- **log_parameters**:  Logs the parameters used in the experiment to the provenance data.\n",
    "\n",
    "When defining the dataset transformations, datasets and data loaders, prov4ml allows logging of relevant information through the `log_dataset`  and `log_param` functions. \n",
    "- **log_dataset**: Logs various information extracted from the dataset used in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28 * 28, 10), \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = transforms.Compose([\n",
    "    transforms.RandomRotation(10), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "prov4ml.log_param(\"dataset transformation\", tform)\n",
    "\n",
    "train_ds = MNIST(PATH_DATASETS, train=True, download=True, transform=tform)\n",
    "test_ds = MNIST(PATH_DATASETS, train=False, download=True, transform=tform)\n",
    "train_ds = Subset(train_ds, range(BATCH_SIZE*4))\n",
    "test_ds = Subset(test_ds, range(BATCH_SIZE*2))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "prov4ml.log_dataset(train_loader, \"train_ds\")\n",
    "prov4ml.log_dataset(test_loader, \"test_ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model\n",
    "\n",
    "Train the MNIST model using PyTorch, then log the final model version using prov4ml, and evaluate the model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 29.95it/s]\n",
      "2it [00:00, 213.47it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mnist_model = MNISTModel()\n",
    "optim = torch.optim.Adam(mnist_model.parameters(), lr=0.0002)\n",
    "prov4ml.log_param(\"optimizer\", \"Adam\")\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        y_hat = mnist_model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        prov4ml.log_metric(\"MSE_train\", loss, context=prov4ml.Context.TRAINING, step=epoch)\n",
    "    \n",
    "    prov4ml.log_carbon_metrics(prov4ml.Context.TRAINING, step=epoch)\n",
    "    prov4ml.log_system_metrics(prov4ml.Context.TRAINING, step=epoch)\n",
    "    prov4ml.save_model_version(mnist_model, f\"mnist_model_version_{epoch}\", prov4ml.Context.TRAINING, epoch)\n",
    "        \n",
    "for i, (x, y) in tqdm(enumerate(test_loader)):\n",
    "    y_hat = mnist_model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    prov4ml.log_metric(\"MSE_test\", loss, prov4ml.Context.EVALUATION, step=epoch)\n",
    "\n",
    "prov4ml.log_model(mnist_model, \"mnist_model_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closing the run and saving the model as ProvJSON\n",
    "\n",
    "Save the provenance data to a ProvJSON file for further analysis and visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git not found, skipping commit hash retrieval\n"
     ]
    }
   ],
   "source": [
    "prov4ml.end_run(create_graph=True, create_svg=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
